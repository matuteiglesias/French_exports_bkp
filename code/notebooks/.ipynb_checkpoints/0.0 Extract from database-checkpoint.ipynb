{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from database\n",
    "\n",
    "This notebook contains all queries to the source database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from functions import chunk, agg, finalize\n",
    "tunique = dd.Aggregation('tunique', chunk, agg,finalize)\n",
    "first = dd.Aggregation('first', chunk, agg,finalize)\n",
    "\n",
    "# %load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_path = './../../../../../media/miglesia/Elements/export_france/data/type1/DP1610_MAASTRICHT1_1997_2013/'\n",
    "# save_path = './../../../../../media/miglesia/Elements/export_france/data/processed/'\n",
    "save_path = './../../../../../media/miglesia/Elements/export_france/data/processed/'\n",
    "\n",
    "colnames = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'DEPT', u'CN ID 8', u'CPA6',\n",
    "       u'PYOD', u'PAYP', u'VAT', u'PRIFAC', u'DEVFAC', u'VFTE', u'VART', u'D_MASSE', u'MASSE', u'USUP', u'USUP_MT']\n",
    "colname_no = dict(zip(colnames, range(18)))\n",
    "\n",
    "def get_data(columns, drive_path, start_year = 1997, end_year = 2014):\n",
    "    df_list = []\n",
    "    for y in range(start_year, end_year):\n",
    "        df_list += [dd.read_table(drive_path+'DP1610_MAASTRICHT1_'+str(y)+'.txt', \n",
    "                usecols = map(colname_no.get, columns),\n",
    "                delimiter = ';', header = None, dtype = {9: 'object'})]\n",
    "    data = dd.concat(df_list)\n",
    "    data.columns = columns\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print for latex\n",
    "\n",
    "# df = get_data(colnames, drive_path, end_year = 1998)\n",
    "# print(df.sample(frac = 0.000001).compute().to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets\n",
    "### - Price and quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed |  8.1s"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'CN ID 8', u'PYOD', u'VART', u'MASSE', u'USUP', u'USUP_MT']\n",
    "\n",
    "data_ = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "grouped = data_.loc[data_.FLUX == 2].groupby(['ID', 'CN ID 8', 'MONTH', 'YEAR'])\n",
    "\n",
    "with ProgressBar():\n",
    "    yearly_qv = grouped[['VART', 'MASSE']].sum().compute()\n",
    "yearly_qv.to_csv(save_path + 'units_qv.csv')\n",
    "\n",
    "# with ProgressBar():\n",
    "#     yearly_details = data_.loc[data_.FLUX == 2].head(1000).groupby(['ID', 'CN ID 8', 'YEAR']).agg(\n",
    "#         {'VART': sum, 'MASSE': sum, 'USUP': tunique, 'USUP': first, 'USUP_MT': sum}).compute()\n",
    "# yearly_details.to_csv(save_path + 'units_detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'units_qv.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Price and quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'DEPT', 'CN ID 8', 'VART']\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "CN_full = pd.read_csv('./../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "data = data.groupby(['ID', 'CN ID 4', 'YEAR', 'DEPT'])[['VART']].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    df = data.compute()\n",
    "\n",
    "df.to_csv(save_path + '_transactions_location.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Firm sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'VAT', u'VART']\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "firm_sizes = data.groupby(['ID', 'IMPORT','YEAR'])[['VART']].sum().reset_index()\n",
    "buyr_sizes = data.groupby(['VAT', 'IMPORT','YEAR'])[['VART']].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    firm_sizes = firm_sizes.compute()\n",
    "    buyr_sizes = buyr_sizes.compute()\n",
    "    \n",
    "\n",
    "firm_sizes.to_csv(save_path + 'firm_sizes.csv', index = False)\n",
    "buyr_sizes.to_csv(save_path + 'buyr_sizes.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'buyr_sizes_99.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Value of buyer-seller links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'VAT', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "links = data.groupby(['IMPORT','YEAR','ID','VAT'])['VART'].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    out = links.compute()\n",
    "out.to_csv(save_path + 'buyer_seller_link_value.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'buyer_seller_link_value.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Sourcing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'CN ID 8', 'PYOD', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "data['QUARTER'] = ((data['MONTH'] -1)// 3) + 1\n",
    "\n",
    "CN_full = pd.read_csv('./../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "# Compute and save\n",
    "# sourcing_strategies = data.loc[data.IMPORT == 1].groupby(['YEAR', 'ID', 'CN ID 4', 'PYOD'])[['VART']].sum() #rm QUARTER for yearly dataset\n",
    "# with ProgressBar():\n",
    "#     out = sourcing_strategies.compute()\n",
    "# out.to_csv(save_path + 'sourcing_strategies_99.csv')\n",
    "\n",
    "# export_bundles = data.loc[data.IMPORT == 0].groupby(['YEAR', 'ID', 'CN ID 4', 'PYOD'])[['VART']].sum()\n",
    "# with ProgressBar():\n",
    "#     out2 = export_bundles.compute()\n",
    "# out2.to_csv(save_path + 'export_bundles_99.csv')\n",
    "\n",
    "# Compute and save\n",
    "sourcing_strategies_qr = data.loc[data.IMPORT == 1].groupby(['YEAR', 'QUARTER','ID', 'CN ID 4', 'PYOD'])[['VART']].sum() #rm QUARTER for yearly dataset\n",
    "with ProgressBar():\n",
    "    out = sourcing_strategies_qr.compute()\n",
    "out.to_csv(save_path + 'sourcing_strategies_qr.csv')\n",
    "\n",
    "export_bundles_qr = data.loc[data.IMPORT == 0].groupby(['YEAR', 'QUARTER', 'ID', 'CN ID 4', 'PYOD'])[['VART']].sum()\n",
    "with ProgressBar():\n",
    "    out2 = export_bundles_qr.compute()\n",
    "out2.to_csv(save_path + 'export_bundles_qr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'sourcing_strategies_qr.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bernard's margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's failing for some reason\n",
    "\n",
    "# columns = [u'YEAR', u'FLUX', u'ID', u'VAT', 'CN ID 8', 'PYOD', u'VART']\n",
    "columns = [u'YEAR', u'FLUX', u'ID', u'CN ID 8', 'PYOD',  u'VAT', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "CN_full = pd.read_csv('./../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4']])#.persist()\n",
    "\n",
    "# margins_info = data.groupby(['IMPORT','YEAR','ID']).agg({'VAT': tunique, 'PYOD': tunique, 'CN ID 4': tunique, 'VART': sum})\n",
    "data = data.loc[data.FLUX == 4].groupby(['IMPORT', 'YEAR', 'ID', 'VAT', 'CN ID 8'])['VART'].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    out = data.compute()\n",
    "out.to_csv(save_path + 'bernards_margins_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.FLUX == 4].head()#.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Krammar's determinants of diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'CN ID 8', u'PYOD', u'VAT', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "data = data.loc[data.FLUX == 4]\n",
    "\n",
    "grouped = data.groupby(['ID', 'YEAR', 'IMPORT'])\n",
    "\n",
    "with ProgressBar():\n",
    "    df = grouped.agg({'VART': 'sum','CN ID 8': tunique, u'PYOD': tunique, u'VAT': tunique}).compute()\n",
    "\n",
    "df.to_csv(save_path + 'dets_of_diversification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'dets_of_diversification.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Buyers and sellers by foreign country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'PYOD', u'VART']\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "data_by_dest = data.groupby(['IMPORT','YEAR','ID','PYOD'])['VART'].sum().reset_index()\n",
    "\n",
    "result = data_by_dest.groupby(['PYOD', 'YEAR']).agg({'ID': tunique, 'VART': 'sum'})\n",
    "\n",
    "with ProgressBar():\n",
    "    out = result.compute()\n",
    "    \n",
    "out.to_csv(save_path + 'destination.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 3\n",
    "# assortativity_res = []\n",
    "ID_degree_res = []\n",
    "VAT_degree_res = []\n",
    "\n",
    "for window in [1, 3]:\n",
    "    gap = (window-1)/2\n",
    "    center_years = arange(1997, 2014, 2)\n",
    "    print window\n",
    "\n",
    "    for Yc in center_years:\n",
    "        print Yc\n",
    "        data_sec = data.loc[data.YEAR - Yc <= gap]\n",
    "#         data_sec.groupby(['ID', 'VAT']).agg({'VART': sum })\n",
    "\n",
    "        data_sec_by_ID = data_sec.groupby(['ID']).agg({'VAT': tunique, 'VART': sum})\n",
    "\n",
    "        ID_degree = data_sec_by_ID[['VAT']].reset_index()\n",
    "        ID_degree.columns = [u'ID', u'ID_degree']\n",
    "        ID_degree['center_year'] = Yc\n",
    "        ID_degree['window'] = window\n",
    "        \n",
    "        with ProgressBar():\n",
    "            ID_deg = ID_degree.compute()\n",
    "            ID_deg['bin'] = pd.cut(log10(ID_deg['ID_degree']), bins = arange(-.49, 5.99, .25))\n",
    "            ID_deg.to_csv(save_path + 'ID_deg_'+str(Yc)+'_'+str(window)+'.csv', index = False)\n",
    "#         ID_degree_res += [ID_degree]     \n",
    "\n",
    "#         ID_deg = pd.read_csv()\n",
    "        sampling = ID_deg.groupby(['bin'], observed = True).apply(lambda x: x.sample(200, replace = True))\n",
    "\n",
    "        data_sec_sample = data_sec.loc[data_sec.ID.isin(sampling['ID'].values)]\n",
    "        data_sec_by_VAT = data_sec_sample.groupby(['VAT']).agg({'ID': tunique, 'VART': sum})\n",
    "\n",
    "        VAT_degree = data_sec_by_VAT[['ID']].reset_index()\n",
    "        VAT_degree.columns = [u'VAT', u'VAT_degree']\n",
    "        VAT_degree['center_year'] = Yc\n",
    "        VAT_degree['window'] = window\n",
    "        VAT_degree_res += [VAT_degree]\n",
    "        with ProgressBar():\n",
    "            VAT_deg = VAT_degree.compute()\n",
    "            VAT_deg.to_csv(save_path + 'VAT_deg_'+str(Yc)+'_'+str(window)+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'ID_deg_'+str(Yc)+'_'+str(window)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1)\n",
    "# df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.25).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "# df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.5).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "# df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.75).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "\n",
    "# # df_degrees.groupby('ID_nunique_bin')['VAT_nunique','ID_nunique'].mean().plot(x = 'ID_nunique', y = 'VAT_nunique', marker = 'o', ax = ax)\n",
    "# df_degrees.groupby('ID_nunique')['VAT_nunique'].median().plot(x = 'index', y = 'VAT_nunique', marker = '.', linewidth = 0, ax = ax)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = pd.read_csv(save_path + 'buyer_seller_link_value.csv')\n",
    "# links['PERIOD'] = (links['YEAR'] - 1996) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degrees = links.groupby(['PERIOD', 'ID'])[['VAT']].nunique().rename(columns = {'VAT': 'ID_degree'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import log10, arange\n",
    "# degrees['log_ID_degree'] = log10(degrees['ID_degree'])\n",
    "# degrees['bin_ID_degree'] = pd.cut(degrees['log_ID_degree'], arange(-.25, 4.5, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree_dist = degrees.reset_index().groupby(['PERIOD', 'bin_ID_degree'])[['ID']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig, axs = plt.subplots(1, 2, figsize =(15, 6))\n",
    "\n",
    "# ax = axs[0]\n",
    "# for t in links['PERIOD'].unique():\n",
    "#     log10(degree_dist.loc[t]).reset_index().plot(marker = 'o', linewidth = 0, ax = ax, mec = 'None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
